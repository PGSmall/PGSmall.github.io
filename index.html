<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Gensheng Pei (裴根生)</title>
    <style>
        #clustrmaps-container {
            width: 180px;
            height: 120px;
            margin-top: 20px;
        }
    </style>
</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Gensheng Pei (裴根生)</h1><hr>
<td id="layout-menu">
    <div class="menu-item"><a href="index.html" class="current">Home</a></div>
    <div class="menu-item"><a href="publication.html">Publications</a></div>
    <div class="menu-item"><a href="service.html">Services</a></div>
    <div class="menu-item"><a href="misc.html">Miscellaneous</a></div>
    <div id="clustrmaps-container">
        <!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=W9lniDhZ_RrT5JW68mojgFFoarrq-23Uq6ZY44t7vgg&cl=ffffff&w=a"></script> -->
        <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=W9lniDhZ_RrT5JW68mojgFFoarrq-23Uq6ZY44t7vgg"></script>
    </div>
</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Home</h1><br>
    <p>[ <a href="#bio">Short Bio</a>,
         <a href="#news">News</a>,
         <a href="#interest">Research Interests</a>,
         <!-- <a href="#job">Job Experience</a>, -->
         <a href="#edu">Education</a> ]</p>

    <table class="imgtable"><tr valign="top">
        <td><img src="pgs.png" alt="Gensheng Pei" style="width:auto; height:10em" /></td>
        <td align="left">
            <p><span style="font-size: 125%"><b>Gensheng Pei, Ph.D. Candidate</b></span></p>
            <p>
                School of Computer Science and Engineering,<br>
                Nanjing University of Science and Technology,<br>
                <a href="http://www.milab-nust.com/" target="_blank">MILab.</a>
            </p>
            <p>
                E-mail: peigsh@njust.edu.cn<br>
                [ <a href="https://scholar.google.com/citations?user=ihU_QpsAAAAJ&hl=en" target="_blank">Google Scholar</a>,
                  <a href="https://orcid.org/0000-0002-7677-7487" target="_blank">ORCID</a>,
                  <a href="https://dblp.org/pid/243/3679.html" target="_blank">DBLP</a>]
            </p>
        </td>
    </tr></table>
    
    <div>
        <h2><hr><a name="bio"></a>Short Bio</h2>
        <p>
            I am currently pursuing the Ph.D. degree in <a href="http://www.milab-nust.com/" target="_blank">MILab</a>, the School of Computer Science and Engineering at Nanjing University of Science and Technology under the supervision of Prof. <a href="http://www.milab-nust.com/milab/web/currentmembershow.html?id=1" target="_blank">Zhenmin Tang</a> and Prof. <a href="http://www.milab-nust.com/milab/web/currentmembershow.html?id=18" target="_blank">Yazhou Yao</a>. 
            Before that I received my M.S. degree from the School of Computer and Information, Anqing Normal University, advised by Prof. Yibin Wang.
        </p>
    </div>
    
    <div>
        <h2><hr><a name="news"></a>News</h2>
        <ul>
            <li><p>
                2025/06: Our paper “<a href="https://iccv.thecvf.com/" target="_blank">Cycle-Consistent Learning for Joint Layout-to-Image Generation and Object Detection</a>” is accepted by ICCV 2025.
            </p></li>
            <li><p>
                2025/02: Our paper “<a href="https://openaccess.thecvf.com/content/CVPR2025/html/Pei_Seeing_What_Matters_Empowering_CLIP_with_Patch_Generation-to-Selection_CVPR_2025_paper.html" target="_blank">Seeing What Matters: Empowering CLIP with Patch Generation-to-Selection</a>” is accepted by CVPR 2025.
            </p></li>
            <li><p>
                2024/07: Our paper “<a href="https://dl.acm.org/doi/10.1145/3664647.3680835" target="_blank">Enhancing Robustness in Learning with Noisy Labels: An Asymmetric Co-Training Approach</a>” is accepted by ACM-MM 2024.
            </p></li>
            <li><p>
                2024/04: Our paper “<a href="https://www.sciencedirect.com/science/article/pii/S1566253524002033" target="_blank">LTFormer: A Light-weight Transformer-based Self-supervised Matching Network for Heterogeneous Remote Sensing Images</a>” is accepted by Information Fusion.
            </p></li>
            <li><p>
                2024/03: Our paper “<a href="https://ieeexplore.ieee.org/abstract/document/10687775" target="_blank">Universal Organizer of Segment Anything Model for Unsupervised Semantic Segmentation</a>” is accepted by ICME 2024.
            </p></li>
            <li><p>
                2024/03: Our paper “<a href="https://ieeexplore.ieee.org/abstract/document/10687791" target="_blank">Relating CNN-Transformer Fusion Network for Remote Sensing Change Detection</a>” is accepted by ICME 2024.
            </p></li>
            <li><p>
                2024/02: Our paper “<a href="https://openaccess.thecvf.com/content/CVPR2024/html/Pei_VideoMAC_Video_Masked_Autoencoders_Meet_ConvNets_CVPR_2024_paper.html" target="_blank">VideoMAC: Video Masked Autoencoders Meet ConvNets</a>” is accepted by CVPR 2024.
            </p></li>
            <li><p>
                2023/10: Our paper “<a href="https://ieeexplore.ieee.org/abstract/document/10298026" target="_blank">Hierarchical Graph Pattern Understanding for Zero-Shot Video Object Segmentation</a>” is accepted by TIP.
            </p></li>
            <li><p>
                2023/05: Our paper “<a href="https://academic.oup.com/nsr/advance-article/doi/10.1093/nsr/nwad122/7152628" target="_blank">Automated Object Recognition in High-resolution Optical Remote Sensing Imagery</a>” is accepted by NSR.
            </p></li>
            <li><p>
                2023/04: Our paper “<a href="https://ieeexplore.ieee.org/abstract/document/10105896" target="_blank">Hierarchical Co-attention Propagation Network for Zero-Shot Video Object Segmentation</a>” is accepted by TIP.
            </p></li>
            <li><p>
                2022/07: Our paper “<a href="https://link.springer.com/chapter/10.1007/978-3-031-19830-4_34" target="_blank">Hierarchical Feature Alignment Network for Unsupervised Video Object Segmentation</a>” is accepted by ECCV 2022.
            </p></li>
        </ul>
    </div>

    <div>
        <h2><hr><a name="interest"></a>Research Interests</h2>
        <ul>
            <li><p><b>Video segmentation</b> (including but not limited to<br>
                unsupervised learning, semi-supervised learning, and self-supervised learning)</p></li>
            <li><p>Change detection</p></li>
            <li><p>Self-supervised learning</p></li>
            <li><p>Vision-Language Model</p></li>
        </ul>
    </div>

    <div>
        <h2><hr><a name="edu"></a>Education</h2>
        <ul>
            <li><p>
                <b>Doctor of Engineering</b>, April 2025<br>
                School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China.<br>
                Supervised by Prof. Zhenmin Tang.
            </p></li>
            <li><p>
                <b>Master of Science</b>, July 2019<br>
                School of Computer and Information, Anqing Normal University, Anqing, China.<br>
                Supervised by Prof. Yibin Wang.
            </p></li>
            <li><p>
                <b>Bachelor of Engineering</b>, July 2016<br>
                School of Computer and Information, Anqing Normal University, Anqing, China.
            </p></li>
        </ul>
    </div>
</td>
</tr>
</table>
</body>
</html>

<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Gensheng Pei (裴根生)</title>
</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Gensheng Pei (裴根生)</h1><hr>
<td id="layout-menu">
    <div class="menu-item"><a href="index.html" class="current">Home</a></div>
    <div class="menu-item"><a href="publication.html">Publications</a></div>
    <div class="menu-item"><a href="service.html">Services</a></div>
    <div class="menu-item"><a href="misc.html">Miscellaneous</a></div>
</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Home</h1><br>
    <p>[ <a href="#bio">Short Bio</a>,
         <a href="#news">News</a>,
         <a href="#interest">Research Interests</a>,
         <!-- <a href="#job">Job Experience</a>, -->
         <a href="#edu">Education</a> ]</p>

    <table class="imgtable"><tr valign="top">
        <td><img src="pgs.png" alt="Gensheng Pei" style="width:auto; height:10em" /></td>
        <td align="left">
            <p><span style="font-size: 125%"><b>Gensheng Pei, Ph.D. Candidate</b></span></p>
            <p>
                School of Computer Science and Engineering,<br>
                Nanjing University of Science and Technology,<br>
                <a href="http://www.milab-nust.com/" target="_blank">MILab.</a>
            </p>
            <p>
                E-mail: peigsh@njust.edu.cn<br>
                [ <a href="https://scholar.google.com/citations?user=ihU_QpsAAAAJ&hl=en" target="_blank">Google Scholar</a>,
                  <a href="https://orcid.org/0000-0002-7677-7487" target="_blank">ORCID</a>,
                  <a href="https://dblp.org/pid/243/3679.html" target="_blank">DBLP</a>]
            </p>
        </td>
    </tr></table>
    
    <div>
        <h2><hr><a name="bio"></a>Short Bio</h2>
        <p>
            I am currently pursuing the Ph.D. degree in <a href="http://www.milab-nust.com/" target="_blank">MILab</a>, the School of Computer Science and Engineering at Nanjing University of Science and Technology under the supervision of Prof. <a href="http://www.milab-nust.com/milab/web/currentmembershow.html?id=1" target="_blank">Zhenmin Tang</a> and Prof. <a href="http://www.milab-nust.com/milab/web/currentmembershow.html?id=18" target="_blank">Yazhou Yao</a>. 
            Before that I received my M.S. degree from the School of Computer and Information, Anqing Normal University, advised by Prof. Yibin Wang.
        </p>
    </div>
    
    <div>
        <h2><hr><a name="news"></a>News</h2>
        <ul>
            <li><p>
                2024/04: Our paper “<a href="https://www.sciencedirect.com/science/article/pii/S1566253524002033" target="_blank">LTFormer: A Light-weight Transformer-based Self-supervised Matching Network for Heterogeneous Remote Sensing Images</a>” is accepted by Information Fusion.
            </p></li>
            <li><p>
                2024/02: Our paper “<a href="https://arxiv.org/abs/2402.19082" target="_blank">VideoMAC: Video Masked Autoencoders Meet ConvNets</a>” is accepted by CVPR 2024.
            </p></li>
            <li><p>
                2023/10: Our paper “<a href="https://ieeexplore.ieee.org/abstract/document/10298026" target="_blank">Hierarchical Graph Pattern Understanding for Zero-Shot Video Object Segmentation</a>” is accepted by TIP.
            </p></li>
            <li><p>
                2023/05: Our paper “<a href="https://academic.oup.com/nsr/advance-article/doi/10.1093/nsr/nwad122/7152628" target="_blank">Automated Object Recognition in High-resolution Optical Remote Sensing Imagery</a>” is accepted by NSR.
            </p></li>
            <li><p>
                2023/04: Our paper “<a href="https://ieeexplore.ieee.org/abstract/document/10105896" target="_blank">Hierarchical Co-attention Propagation Network for Zero-Shot Video Object Segmentation</a>” is accepted by TIP.
            </p></li>
            <li><p>
                2022/07: Our paper “<a href="https://link.springer.com/chapter/10.1007/978-3-031-19830-4_34" target="_blank">Hierarchical Feature Alignment Network for Unsupervised Video Object Segmentation</a>” is accepted by ECCV 2022.
            </p></li>
        </ul>
    </div>

    <div>
        <h2><hr><a name="interest"></a>Research Interests</h2>
        <ul>
            <li><p><b>Video segmentation</b> (including but not limited to<br>
                unsupervised learning, semi-supervised learning, and self-supervised learning)</p></li>
            <li><p>Change detection</p></li>
            <li><p>Self-supervised learning</p></li>
        </ul>
    </div>

    <div>
        <h2><hr><a name="edu"></a>Education</h2>
        <ul>
            <!-- <li><p>
                <b>Doctor of Engineering</b>, July 2024<br>
                School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China.<br>
                Supervised by Prof. Zhenmin Tang.
            </p></li> -->
            <li><p>
                <b>Master of Science</b>, July 2019<br>
                School of Computer and Information, Anqing Normal University, Anqing, China.<br>
                Supervised by Prof. Yibin Wang.
            </p></li>
            <li><p>
                <b>Bachelor of Engineering</b>, July 2016<br>
                School of Computer and Information, Anqing Normal University, Anqing, China.
            </p></li>
        </ul>
    </div>
</td>
</tr>
</table>
</body>
</html>
